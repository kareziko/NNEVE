{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NNEVE # Neural network based eigenvalue estimator for quantum oscillator problem. Documentation # Online documentation is available at argmaster.github.io/NNEVE/ To build docs locally run tox -e docs","title":"Home"},{"location":"#nneve","text":"Neural network based eigenvalue estimator for quantum oscillator problem.","title":"NNEVE"},{"location":"#documentation","text":"Online documentation is available at argmaster.github.io/NNEVE/ To build docs locally run tox -e docs","title":"Documentation"},{"location":"changelog/","text":"Changelog # All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [1.0.0] - 2022-MM-DD #","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#100-2022-mm-dd","text":"","title":"[1.0.0] - 2022-MM-DD"},{"location":"license/","text":"GNU LESSER GENERAL PUBLIC LICENSE # Version 3, 29 June 2007 Copyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/ Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. This version of the GNU Lesser General Public License incorporates the terms and conditions of version 3 of the GNU General Public License, supplemented by the additional permissions listed below. 0. Additional Definitions. # As used herein, \"this License\" refers to version 3 of the GNU Lesser General Public License, and the \"GNU GPL\" refers to version 3 of the GNU General Public License. \"The Library\" refers to a covered work governed by this License, other than an Application or a Combined Work as defined below. An \"Application\" is any work that makes use of an interface provided by the Library, but which is not otherwise based on the Library. Defining a subclass of a class defined by the Library is deemed a mode of using an interface provided by the Library. A \"Combined Work\" is a work produced by combining or linking an Application with the Library. The particular version of the Library with which the Combined Work was made is also called the \"Linked Version\". The \"Minimal Corresponding Source\" for a Combined Work means the Corresponding Source for the Combined Work, excluding any source code for portions of the Combined Work that, considered in isolation, are based on the Application, and not on the Linked Version. The \"Corresponding Application Code\" for a Combined Work means the object code and/or source code for the Application, including any data and utility programs needed for reproducing the Combined Work from the Application, but excluding the System Libraries of the Combined Work. 1. Exception to Section 3 of the GNU GPL. # You may convey a covered work under sections 3 and 4 of this License without being bound by section 3 of the GNU GPL. 2. Conveying Modified Versions. # If you modify a copy of the Library, and, in your modifications, a facility refers to a function or data to be supplied by an Application that uses the facility (other than as an argument passed when the facility is invoked), then you may convey a copy of the modified version: a) under this License, provided that you make a good faith effort to ensure that, in the event an Application does not supply the function or data, the facility still operates, and performs whatever part of its purpose remains meaningful, or b) under the GNU GPL, with none of the additional permissions of this License applicable to that copy. 3. Object Code Incorporating Material from Library Header Files. # The object code form of an Application may incorporate material from a header file that is part of the Library. You may convey such object code under terms of your choice, provided that, if the incorporated material is not limited to numerical parameters, data structure layouts and accessors, or small macros, inline functions and templates (ten or fewer lines in length), you do both of the following: a) Give prominent notice with each copy of the object code that the Library is used in it and that the Library and its use are covered by this License. b) Accompany the object code with a copy of the GNU GPL and this license document. 4. Combined Works. # You may convey a Combined Work under terms of your choice that, taken together, effectively do not restrict modification of the portions of the Library contained in the Combined Work and reverse engineering for debugging such modifications, if you also do each of the following: a) Give prominent notice with each copy of the Combined Work that the Library is used in it and that the Library and its use are covered by this License. b) Accompany the Combined Work with a copy of the GNU GPL and this license document. c) For a Combined Work that displays copyright notices during execution, include the copyright notice for the Library among these notices, as well as a reference directing the user to the copies of the GNU GPL and this license document. d) Do one of the following: - 0) Convey the Minimal Corresponding Source under the terms of this License, and the Corresponding Application Code in a form suitable for, and under terms that permit, the user to recombine or relink the Application with a modified version of the Linked Version to produce a modified Combined Work, in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source. - 1) Use a suitable shared library mechanism for linking with the Library. A suitable mechanism is one that (a) uses at run time a copy of the Library already present on the user's computer system, and (b) will operate properly with a modified version of the Library that is interface-compatible with the Linked Version. e) Provide Installation Information, but only if you would otherwise be required to provide such information under section 6 of the GNU GPL, and only to the extent that such information is necessary to install and execute a modified version of the Combined Work produced by recombining or relinking the Application with a modified version of the Linked Version. (If you use option 4d0, the Installation Information must accompany the Minimal Corresponding Source and Corresponding Application Code. If you use option 4d1, you must provide the Installation Information in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source.) 5. Combined Libraries. # You may place library facilities that are a work based on the Library side by side in a single library together with other library facilities that are not Applications and are not covered by this License, and convey such a combined library under terms of your choice, if you do both of the following: a) Accompany the combined library with a copy of the same work based on the Library, uncombined with any other library facilities, conveyed under the terms of this License. b) Give prominent notice with the combined library that part of it is a work based on the Library, and explaining where to find the accompanying uncombined form of the same work. 6. Revised Versions of the GNU Lesser General Public License. # The Free Software Foundation may publish revised and/or new versions of the GNU Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. Each version is given a distinguishing version number. If the Library as you received it specifies that a certain numbered version of the GNU Lesser General Public License \"or any later version\" applies to it, you have the option of following the terms and conditions either of that published version or of any later version published by the Free Software Foundation. If the Library as you received it does not specify a version number of the GNU Lesser General Public License, you may choose any version of the GNU Lesser General Public License ever published by the Free Software Foundation. If the Library as you received it specifies that a proxy can decide whether future versions of the GNU Lesser General Public License shall apply, that proxy's public statement of acceptance of any version is permanent authorization for you to choose that version for the Library.","title":"License"},{"location":"license/#gnu-lesser-general-public-license","text":"Version 3, 29 June 2007 Copyright (C) 2007 Free Software Foundation, Inc. https://fsf.org/ Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. This version of the GNU Lesser General Public License incorporates the terms and conditions of version 3 of the GNU General Public License, supplemented by the additional permissions listed below.","title":"GNU LESSER GENERAL PUBLIC LICENSE"},{"location":"license/#0-additional-definitions","text":"As used herein, \"this License\" refers to version 3 of the GNU Lesser General Public License, and the \"GNU GPL\" refers to version 3 of the GNU General Public License. \"The Library\" refers to a covered work governed by this License, other than an Application or a Combined Work as defined below. An \"Application\" is any work that makes use of an interface provided by the Library, but which is not otherwise based on the Library. Defining a subclass of a class defined by the Library is deemed a mode of using an interface provided by the Library. A \"Combined Work\" is a work produced by combining or linking an Application with the Library. The particular version of the Library with which the Combined Work was made is also called the \"Linked Version\". The \"Minimal Corresponding Source\" for a Combined Work means the Corresponding Source for the Combined Work, excluding any source code for portions of the Combined Work that, considered in isolation, are based on the Application, and not on the Linked Version. The \"Corresponding Application Code\" for a Combined Work means the object code and/or source code for the Application, including any data and utility programs needed for reproducing the Combined Work from the Application, but excluding the System Libraries of the Combined Work.","title":"0. Additional Definitions."},{"location":"license/#1-exception-to-section-3-of-the-gnu-gpl","text":"You may convey a covered work under sections 3 and 4 of this License without being bound by section 3 of the GNU GPL.","title":"1. Exception to Section 3 of the GNU GPL."},{"location":"license/#2-conveying-modified-versions","text":"If you modify a copy of the Library, and, in your modifications, a facility refers to a function or data to be supplied by an Application that uses the facility (other than as an argument passed when the facility is invoked), then you may convey a copy of the modified version: a) under this License, provided that you make a good faith effort to ensure that, in the event an Application does not supply the function or data, the facility still operates, and performs whatever part of its purpose remains meaningful, or b) under the GNU GPL, with none of the additional permissions of this License applicable to that copy.","title":"2. Conveying Modified Versions."},{"location":"license/#3-object-code-incorporating-material-from-library-header-files","text":"The object code form of an Application may incorporate material from a header file that is part of the Library. You may convey such object code under terms of your choice, provided that, if the incorporated material is not limited to numerical parameters, data structure layouts and accessors, or small macros, inline functions and templates (ten or fewer lines in length), you do both of the following: a) Give prominent notice with each copy of the object code that the Library is used in it and that the Library and its use are covered by this License. b) Accompany the object code with a copy of the GNU GPL and this license document.","title":"3. Object Code Incorporating Material from Library Header Files."},{"location":"license/#4-combined-works","text":"You may convey a Combined Work under terms of your choice that, taken together, effectively do not restrict modification of the portions of the Library contained in the Combined Work and reverse engineering for debugging such modifications, if you also do each of the following: a) Give prominent notice with each copy of the Combined Work that the Library is used in it and that the Library and its use are covered by this License. b) Accompany the Combined Work with a copy of the GNU GPL and this license document. c) For a Combined Work that displays copyright notices during execution, include the copyright notice for the Library among these notices, as well as a reference directing the user to the copies of the GNU GPL and this license document. d) Do one of the following: - 0) Convey the Minimal Corresponding Source under the terms of this License, and the Corresponding Application Code in a form suitable for, and under terms that permit, the user to recombine or relink the Application with a modified version of the Linked Version to produce a modified Combined Work, in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source. - 1) Use a suitable shared library mechanism for linking with the Library. A suitable mechanism is one that (a) uses at run time a copy of the Library already present on the user's computer system, and (b) will operate properly with a modified version of the Library that is interface-compatible with the Linked Version. e) Provide Installation Information, but only if you would otherwise be required to provide such information under section 6 of the GNU GPL, and only to the extent that such information is necessary to install and execute a modified version of the Combined Work produced by recombining or relinking the Application with a modified version of the Linked Version. (If you use option 4d0, the Installation Information must accompany the Minimal Corresponding Source and Corresponding Application Code. If you use option 4d1, you must provide the Installation Information in the manner specified by section 6 of the GNU GPL for conveying Corresponding Source.)","title":"4. Combined Works."},{"location":"license/#5-combined-libraries","text":"You may place library facilities that are a work based on the Library side by side in a single library together with other library facilities that are not Applications and are not covered by this License, and convey such a combined library under terms of your choice, if you do both of the following: a) Accompany the combined library with a copy of the same work based on the Library, uncombined with any other library facilities, conveyed under the terms of this License. b) Give prominent notice with the combined library that part of it is a work based on the Library, and explaining where to find the accompanying uncombined form of the same work.","title":"5. Combined Libraries."},{"location":"license/#6-revised-versions-of-the-gnu-lesser-general-public-license","text":"The Free Software Foundation may publish revised and/or new versions of the GNU Lesser General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. Each version is given a distinguishing version number. If the Library as you received it specifies that a certain numbered version of the GNU Lesser General Public License \"or any later version\" applies to it, you have the option of following the terms and conditions either of that published version or of any later version published by the Free Software Foundation. If the Library as you received it does not specify a version number of the GNU Lesser General Public License, you may choose any version of the GNU Lesser General Public License ever published by the Free Software Foundation. If the Library as you received it specifies that a proxy can decide whether future versions of the GNU Lesser General Public License shall apply, that proxy's public statement of acceptance of any version is permanent authorization for you to choose that version for the Library.","title":"6. Revised Versions of the GNU Lesser General Public License."},{"location":"develop/docs/","text":"Documentation # Handy links # Markdownguide.org Basic Syntax Markdownguide.org Extended Syntax MkDocs-Material Reference MkDocs # MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. Start by reading the introductory tutorial, then check the User Guide for more information. Main webpage User guide We are also using Material for MkDocs theme for documentation which is a separate package. Main webpage Reference Usage: mkdocs [OPTIONS] COMMAND [ARGS]... MkDocs - Project documentation with Markdown. Options: -V, --version Show the version and exit. -q, --quiet Silence warnings -v, --verbose Enable verbose output -h, --help Show this message and exit. Commands: build Build the MkDocs documentation gh-deploy Deploy your documentation to GitHub Pages new Create a new MkDocs project serve Run the builtin development server Live server # Runs development server, which automatically mirrors changes in source code. Development server is by default available at http://127.0.0.1:8000/ mkdocs serve Full CLI help: Usage: mkdocs serve [OPTIONS] Run the builtin development server Options: -a, --dev-addr <IP:PORT> IP address and port to serve documentation locally (default: localhost:8000) --livereload Enable the live reloading in the development server (this is the default) --no-livereload Disable the live reloading in the development server. --dirtyreload Enable the live reloading in the development server, but only re-build files that have changed --watch-theme Include the theme in list of files to watch for live reloading. Ignored when live reload is not used. -f, --config-file FILENAME Provide a specific MkDocs config -s, --strict Enable strict mode. This will cause MkDocs to abort the build on any warnings. -t, --theme [material|mkdocs|readthedocs] The theme to use when building your documentation. --use-directory-urls / --no-directory-urls Use directory URLs when building pages (the default). -q, --quiet Silence warnings -v, --verbose Enable verbose output -h, --help Show this message and exit. Build documentation # Builds documentation, all generated files are by default saved to site/ folder. mkdocs build Full CLI help: Usage: mkdocs build [OPTIONS] Build the MkDocs documentation Options: -c, --clean / --dirty Remove old files from the site_dir before building (the default). -f, --config-file FILENAME Provide a specific MkDocs config -s, --strict Enable strict mode. This will cause MkDocs to abort the build on any warnings. -t, --theme [mkdocs|material|readthedocs] The theme to use when building your documentation. --use-directory-urls / --no-directory-urls Use directory URLs when building pages (the default). -d, --site-dir PATH The directory to output the result of the documentation build. -q, --quiet Silence warnings -v, --verbose Enable verbose output -h, --help Show this message and exit.","title":"Documentation"},{"location":"develop/docs/#documentation","text":"","title":"Documentation"},{"location":"develop/docs/#handy-links","text":"Markdownguide.org Basic Syntax Markdownguide.org Extended Syntax MkDocs-Material Reference","title":"Handy links"},{"location":"develop/docs/#mkdocs","text":"MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. Start by reading the introductory tutorial, then check the User Guide for more information. Main webpage User guide We are also using Material for MkDocs theme for documentation which is a separate package. Main webpage Reference Usage: mkdocs [OPTIONS] COMMAND [ARGS]... MkDocs - Project documentation with Markdown. Options: -V, --version Show the version and exit. -q, --quiet Silence warnings -v, --verbose Enable verbose output -h, --help Show this message and exit. Commands: build Build the MkDocs documentation gh-deploy Deploy your documentation to GitHub Pages new Create a new MkDocs project serve Run the builtin development server","title":"MkDocs"},{"location":"develop/docs/#live-server","text":"Runs development server, which automatically mirrors changes in source code. Development server is by default available at http://127.0.0.1:8000/ mkdocs serve Full CLI help: Usage: mkdocs serve [OPTIONS] Run the builtin development server Options: -a, --dev-addr <IP:PORT> IP address and port to serve documentation locally (default: localhost:8000) --livereload Enable the live reloading in the development server (this is the default) --no-livereload Disable the live reloading in the development server. --dirtyreload Enable the live reloading in the development server, but only re-build files that have changed --watch-theme Include the theme in list of files to watch for live reloading. Ignored when live reload is not used. -f, --config-file FILENAME Provide a specific MkDocs config -s, --strict Enable strict mode. This will cause MkDocs to abort the build on any warnings. -t, --theme [material|mkdocs|readthedocs] The theme to use when building your documentation. --use-directory-urls / --no-directory-urls Use directory URLs when building pages (the default). -q, --quiet Silence warnings -v, --verbose Enable verbose output -h, --help Show this message and exit.","title":"Live server"},{"location":"develop/docs/#build-documentation","text":"Builds documentation, all generated files are by default saved to site/ folder. mkdocs build Full CLI help: Usage: mkdocs build [OPTIONS] Build the MkDocs documentation Options: -c, --clean / --dirty Remove old files from the site_dir before building (the default). -f, --config-file FILENAME Provide a specific MkDocs config -s, --strict Enable strict mode. This will cause MkDocs to abort the build on any warnings. -t, --theme [mkdocs|material|readthedocs] The theme to use when building your documentation. --use-directory-urls / --no-directory-urls Use directory URLs when building pages (the default). -d, --site-dir PATH The directory to output the result of the documentation build. -q, --quiet Silence warnings -v, --verbose Enable verbose output -h, --help Show this message and exit.","title":"Build documentation"},{"location":"develop/feature/","text":"Feature flow # This project uses GitHub flow as it's main workflow model. Simplified visualization can be seen on graph below: %%{init: { 'theme': 'forest' , 'themeVariables': { 'git0': '#4db85f', 'git1': '#49b391', 'git2': '#59a7ff', 'git3': '#d93261', 'git4': '#00ffff', 'git5': '#ffff00', 'git6': '#ff00ff', 'git7': '#00ffff' } } }%% gitGraph commit tag:\"0.0.0\" branch feature checkout feature branch private checkout private commit commit checkout feature merge private branch private2 checkout private2 commit commit checkout feature merge private2 commit tag:\"1.0.0\" checkout main merge feature Clone repository # Hint You can skip this step if you already have a clone git clone https://github.com/Argmaster/nneve.git Checking out main branch # Make sure we are on main branch. git checkout main Pull changes from origin # Hint You can skip this step if you just cloned the repository git pull --ff Create feature branch # Create new branch for our feature called (replace with whatever you want) feature_name . feature/ prefix is required because of convention. Learn about branches git checkout -b feature/feature_name Check repository status # git status Result should be similar to this: On branch feature/feature_name nothing to commit, working tree clean Commit-test-push cycle # Your work on a feature should be divided into many steps during which you will add new units to the system. Each unit should have a set of tests to verify its operation. Formatting & Quality checks # Run code quality checks with tox to quickly fix most obvious issues in your code. tox -e check tox -e check Run test suite for Python interpreter versions you have locally # Run test suites on available interpreters with tox -e py37 If the tests fail, you have to repeat steps 1 and 2. Omission of the corrections will result in your changes being rejected by the CI tests executed for the pull request. Add all changes to staging area with # git add * You can list file paths instead of using the asterisk symbol if you know you can add many unwanted files. If these unwanted files regularly appear in the codebase, add them to the .gitignore file. Check staging area # git status If any files staged for commit shouldn't be there, unstage them with git restore --staged <file> Commit changes # Now use commit command to send changes to git history git commit This command will open text editor for you, waiting for commit description. You can use git commit -m \"commit message\" to add commit title and omit long description. The commit title should not be longer than 50 characters. - How to write a Git Commit Message - Good Commit Messages: A Practical Git Guide Push changes to remote branch # git push -u origin feature/feature_name For each subsequent push from this branch, you can omit -u origin feature/feature_name git push Create pull request # Visit pull requests and create PR for you feature. Read in GitHub docs about pull requests. Request review & wait for CI checks # Now you can request a pull request review, as it's described here . Before your changes can be merged into another branch, at least one person should see them, and share their thoughts about them with you. If you are prompted to make corrections, do so immediately and do not apply your changes without fixes. Go back to Commit-test-push . You changes should also pass all tests ran by CI system ( Github Actions ). If the tests fail, corrections will also be required before continuing. Merge PR # After receiving a positive response from the reviewer and passing the tests, the pull request can be merged. About merge conflicts About pull request merges .","title":"Feature flow"},{"location":"develop/feature/#feature-flow","text":"This project uses GitHub flow as it's main workflow model. Simplified visualization can be seen on graph below: %%{init: { 'theme': 'forest' , 'themeVariables': { 'git0': '#4db85f', 'git1': '#49b391', 'git2': '#59a7ff', 'git3': '#d93261', 'git4': '#00ffff', 'git5': '#ffff00', 'git6': '#ff00ff', 'git7': '#00ffff' } } }%% gitGraph commit tag:\"0.0.0\" branch feature checkout feature branch private checkout private commit commit checkout feature merge private branch private2 checkout private2 commit commit checkout feature merge private2 commit tag:\"1.0.0\" checkout main merge feature","title":"Feature flow"},{"location":"develop/feature/#clone-repository","text":"Hint You can skip this step if you already have a clone git clone https://github.com/Argmaster/nneve.git","title":"Clone repository"},{"location":"develop/feature/#checking-out-main-branch","text":"Make sure we are on main branch. git checkout main","title":"Checking out main branch"},{"location":"develop/feature/#pull-changes-from-origin","text":"Hint You can skip this step if you just cloned the repository git pull --ff","title":"Pull changes from origin"},{"location":"develop/feature/#create-feature-branch","text":"Create new branch for our feature called (replace with whatever you want) feature_name . feature/ prefix is required because of convention. Learn about branches git checkout -b feature/feature_name","title":"Create feature branch"},{"location":"develop/feature/#check-repository-status","text":"git status Result should be similar to this: On branch feature/feature_name nothing to commit, working tree clean","title":"Check repository status"},{"location":"develop/feature/#commit-test-push-cycle","text":"Your work on a feature should be divided into many steps during which you will add new units to the system. Each unit should have a set of tests to verify its operation.","title":"Commit-test-push cycle"},{"location":"develop/feature/#formatting-quality-checks","text":"Run code quality checks with tox to quickly fix most obvious issues in your code. tox -e check tox -e check","title":"Formatting &amp; Quality checks"},{"location":"develop/feature/#run-test-suite-for-python-interpreter-versions-you-have-locally","text":"Run test suites on available interpreters with tox -e py37 If the tests fail, you have to repeat steps 1 and 2. Omission of the corrections will result in your changes being rejected by the CI tests executed for the pull request.","title":"Run test suite for Python interpreter versions you have locally"},{"location":"develop/feature/#add-all-changes-to-staging-area-with","text":"git add * You can list file paths instead of using the asterisk symbol if you know you can add many unwanted files. If these unwanted files regularly appear in the codebase, add them to the .gitignore file.","title":"Add all changes to staging area with"},{"location":"develop/feature/#check-staging-area","text":"git status If any files staged for commit shouldn't be there, unstage them with git restore --staged <file>","title":"Check staging area"},{"location":"develop/feature/#commit-changes","text":"Now use commit command to send changes to git history git commit This command will open text editor for you, waiting for commit description. You can use git commit -m \"commit message\" to add commit title and omit long description. The commit title should not be longer than 50 characters. - How to write a Git Commit Message - Good Commit Messages: A Practical Git Guide","title":"Commit changes"},{"location":"develop/feature/#push-changes-to-remote-branch","text":"git push -u origin feature/feature_name For each subsequent push from this branch, you can omit -u origin feature/feature_name git push","title":"Push changes to remote branch"},{"location":"develop/feature/#create-pull-request","text":"Visit pull requests and create PR for you feature. Read in GitHub docs about pull requests.","title":"Create pull request"},{"location":"develop/feature/#request-review-wait-for-ci-checks","text":"Now you can request a pull request review, as it's described here . Before your changes can be merged into another branch, at least one person should see them, and share their thoughts about them with you. If you are prompted to make corrections, do so immediately and do not apply your changes without fixes. Go back to Commit-test-push . You changes should also pass all tests ran by CI system ( Github Actions ). If the tests fail, corrections will also be required before continuing.","title":"Request review &amp; wait for CI checks"},{"location":"develop/feature/#merge-pr","text":"After receiving a positive response from the reviewer and passing the tests, the pull request can be merged. About merge conflicts About pull request merges .","title":"Merge PR"},{"location":"develop/formatting/","text":"Code formatting # black # black is the uncompromising Python code formatter. By using it, you agree to cede control over minutiae of hand-formatting. In return, black gives you speed, determinism, and freedom from pycodestyle nagging about formatting. You will save time and mental energy for more important matters. You can view black configuration in pyproject.toml file, in [tool.black] section. Manual usage valid for this project: black . isort # isort your imports, so you don't have to. isort is a Python utility / library to sort imports alphabetically, and automatically separated into sections and by type. You can view isort configuration in .isort.cfg file. Manual usage valid for this project: isort . docformatter # docformatter currently automatically formats docstrings to follow a subset of the PEP 257 conventions. Below are the relevant items quoted from PEP 257. For consistency, always use triple double quotes around docstrings. Triple quotes are used even though the string fits on one line. Multi-line docstrings consist of a summary line just like a one-line docstring, followed by a blank line, followed by a more elaborate description. Unless the entire docstring fits on a line, place the closing quotes on a line by themselves. docformatter also handles some of the PEP 8 conventions. Don\u2019t write string literals that rely on significant trailing whitespace. Such trailing whitespace is visually indistinguishable and some editors (or more recently, reindent.py) will trim them. Manual usage valid for this project: docformatter -r source/ scripts/ --in-place --docstring-length 75 75 -e .tox,.eggs,build,dist,typings,.temp","title":"Formatting code"},{"location":"develop/formatting/#code-formatting","text":"","title":"Code formatting"},{"location":"develop/formatting/#black","text":"black is the uncompromising Python code formatter. By using it, you agree to cede control over minutiae of hand-formatting. In return, black gives you speed, determinism, and freedom from pycodestyle nagging about formatting. You will save time and mental energy for more important matters. You can view black configuration in pyproject.toml file, in [tool.black] section. Manual usage valid for this project: black .","title":"black"},{"location":"develop/formatting/#isort","text":"isort your imports, so you don't have to. isort is a Python utility / library to sort imports alphabetically, and automatically separated into sections and by type. You can view isort configuration in .isort.cfg file. Manual usage valid for this project: isort .","title":"isort"},{"location":"develop/formatting/#docformatter","text":"docformatter currently automatically formats docstrings to follow a subset of the PEP 257 conventions. Below are the relevant items quoted from PEP 257. For consistency, always use triple double quotes around docstrings. Triple quotes are used even though the string fits on one line. Multi-line docstrings consist of a summary line just like a one-line docstring, followed by a blank line, followed by a more elaborate description. Unless the entire docstring fits on a line, place the closing quotes on a line by themselves. docformatter also handles some of the PEP 8 conventions. Don\u2019t write string literals that rely on significant trailing whitespace. Such trailing whitespace is visually indistinguishable and some editors (or more recently, reindent.py) will trim them. Manual usage valid for this project: docformatter -r source/ scripts/ --in-place --docstring-length 75 75 -e .tox,.eggs,build,dist,typings,.temp","title":"docformatter"},{"location":"develop/quality_checks/","text":"Code quality checks # Running single test file To run single test file with pytest pytest tests/test_folder/test_feature.py -rP You can select single test too pytest tests/test_folder/test_feature.py -rP -k test_name flake8 # Flake8 is a wrapper around these tools: PyFlakes which checks Python source files for errors. pycodestyle , a tool to check your Python code against some of the style conventions in PEP 8. Ned Batchelder\u2019s McCabe script for checking McCabe complexity. See list of awesome flake8 plugins List of included 3rd-party plugins: flake8-alfred - warn on unsafe/obsolete symbols. flake8-alphabetize - checker for alphabetizing import and all . flake8-broken-line - forbid backslashes for line breaks. flake8-bugbear - finding likely bugs and design problems in your program. flake8-builtins - check for python builtins being used as variables or parameters. flake8-comprehensions - check for invalid list/set/dict comprehensions. flake8-docstrings - uses pydocstyle to check docstrings flake8-eradicate - find commented out (or so called \"dead\") code. flake8-functions - report on issues with functions. flake8-functions-names - validates function names, decomposition and conformity with annotations. Conventions from here and here . flake8-printf-formatting - forbids printf-style string formatting flake8-pytest-style - checking common style issues or inconsistencies with pytest-based tests. flake8-simplify - helps you simplify your code. pep8-naming - check your code against PEP 8 naming conventions. flake8-expression-complexity - validates expression complexity and stops you from creating monstrous multi-line expressions. flake8-cognitive-complexity - validates cognitive functions complexity. pre-commit # A framework for managing and maintaining multi-language pre-commit hooks. Git hook scripts are useful for identifying simple issues before submission to code review. We run our hooks on every commit to automatically point out issues in code such as missing semicolons, trailing whitespace, and debug statements. By pointing these issues out before code review, this allows a code reviewer to focus on the architecture of a change while not wasting time with trivial style nitpicks. List of hooks # isort black flake8 - flake8-alfred - flake8-alphabetize - flake8-broken-line - flake8-bugbear - flake8-builtins - flake8-comprehensions - flake8-docstrings - flake8-eradicate - flake8-functions - flake8-functions-names - flake8-printf-formatting - flake8-pytest-style - flake8-simplify - pep8-naming - flake8-cognitive-complexity - flake8-expression-complexity docformatter pre-commit-hooks - trailing-whitespace - end-of-file-fixer - debug-statements - check-added-large-file - no-commit-to-branch - requirements-txt-fixer - trailing-whitespace","title":"Quality checks"},{"location":"develop/quality_checks/#code-quality-checks","text":"Running single test file To run single test file with pytest pytest tests/test_folder/test_feature.py -rP You can select single test too pytest tests/test_folder/test_feature.py -rP -k test_name","title":"Code quality checks"},{"location":"develop/quality_checks/#flake8","text":"Flake8 is a wrapper around these tools: PyFlakes which checks Python source files for errors. pycodestyle , a tool to check your Python code against some of the style conventions in PEP 8. Ned Batchelder\u2019s McCabe script for checking McCabe complexity. See list of awesome flake8 plugins List of included 3rd-party plugins: flake8-alfred - warn on unsafe/obsolete symbols. flake8-alphabetize - checker for alphabetizing import and all . flake8-broken-line - forbid backslashes for line breaks. flake8-bugbear - finding likely bugs and design problems in your program. flake8-builtins - check for python builtins being used as variables or parameters. flake8-comprehensions - check for invalid list/set/dict comprehensions. flake8-docstrings - uses pydocstyle to check docstrings flake8-eradicate - find commented out (or so called \"dead\") code. flake8-functions - report on issues with functions. flake8-functions-names - validates function names, decomposition and conformity with annotations. Conventions from here and here . flake8-printf-formatting - forbids printf-style string formatting flake8-pytest-style - checking common style issues or inconsistencies with pytest-based tests. flake8-simplify - helps you simplify your code. pep8-naming - check your code against PEP 8 naming conventions. flake8-expression-complexity - validates expression complexity and stops you from creating monstrous multi-line expressions. flake8-cognitive-complexity - validates cognitive functions complexity.","title":"flake8"},{"location":"develop/quality_checks/#pre-commit","text":"A framework for managing and maintaining multi-language pre-commit hooks. Git hook scripts are useful for identifying simple issues before submission to code review. We run our hooks on every commit to automatically point out issues in code such as missing semicolons, trailing whitespace, and debug statements. By pointing these issues out before code review, this allows a code reviewer to focus on the architecture of a change while not wasting time with trivial style nitpicks.","title":"pre-commit"},{"location":"develop/quality_checks/#list-of-hooks","text":"isort black flake8 - flake8-alfred - flake8-alphabetize - flake8-broken-line - flake8-bugbear - flake8-builtins - flake8-comprehensions - flake8-docstrings - flake8-eradicate - flake8-functions - flake8-functions-names - flake8-printf-formatting - flake8-pytest-style - flake8-simplify - pep8-naming - flake8-cognitive-complexity - flake8-expression-complexity docformatter pre-commit-hooks - trailing-whitespace - end-of-file-fixer - debug-statements - check-added-large-file - no-commit-to-branch - requirements-txt-fixer - trailing-whitespace","title":"List of hooks"},{"location":"develop/tox_basics/","text":"Tox basics # A virtual environment is a Python environment such that the Python interpreter, libraries and scripts installed into it are isolated from those installed in other virtual environments, and (by default) any libraries installed in a \u201csystem\u201d Python, i.e., one which is installed as part of your operating system. What is tox? # tox is a generic virtualenv management and test command line tool you can use for: checking that your package installs correctly with different Python versions and interpreters running your tests in each of the environments, configuring your test tool of choice acting as a frontend to Continuous Integration servers, greatly reducing boilerplate and merging CI and shell-based testing. Handy Links # To read more about tox, visit it's documentation. tox global settings tox environments configuration tox substitutions Generating environments, conditional settings Environmental variables Full tox cli documentation tox examples Our perspective # Every complex Python project requires multiple tools for development and deployment. Those are mostly related to test suite running, checking quality of code, developing and building documentation and building distribution packages. Usually those are tedious tasks and they are at the top of the lists of tasks to automate. Here comes tox tox can be used as a reliable replacement for manually written scripts. It's designed to run predefined series of command in automatically generated Python virtual environment. It was designed for Python ecosystem and is widely used along Python projects. It is compatible with other Python tools out of the box. All the configuration is contained in tox.ini file and is completely static. Basic usage # To invoke single environment with tox you have to memorize one simple command: tox -e envname Where envname is replaced 1:1 with name of any environments listed below. Info You can also use tox command without any arguments to run checks for all supported python versions. Be aware that it is really time consuming. List of all configured environments # Simplicity of creating tox managed environments allows us to create highly specialized environments with minimal boilerplate. devenv # Stands for development environment (important when using IDE like Visual Studio Code or PyCharm). When selecting interpreter for your IDE, devenv is a right one to pick. This environment is meant to contain all tools important for continuos development including linters, formatters, building tools, packaging tools and everything else listed in requirements-dev.txt It is really heavy and expensive to create because of complexity of installation. Every call of tox -e devenv will completely recreate the environment. Danger Running tox -e devenv completely reinstalls environment - it's time consuming. It is designed in such way many due to the fact that during development there is no need to recreate it until something brakes, and then it's handy to simplify reinstallation how much possible. Hint Running this environment will install pre-commit. To select Python from devenv as interpreter in Visual Studio Code, use Ctrl + Shift + P and type Python: Select Interpreter , then hit Enter , select Enter interpreter path , pick Find and navigate to python.exe in .tox/devenv/bin (unix) or .tox/devev/scripts (windows). This environment is rather bullet proof in comparison to other non-utility environments (mainly test runners). It should just install on demand, and every failure should be considered and fixed permanently. List of included dependencies: requirement.txt click> = 8.1.0,<8.2.0 matplotlib> = 3.5.0,<3.6.0 numpy> = 1.21.0,<1.22.0 packaging> = 21.3.0,<21.4.0 pandas> = 1.3.0,<1.4.0 rich> = 12.0.0,<12.1.0 scipy> = 1.7.0,<1.8.0 tensorflow> = 2.8.0,<2.9.0 pillow> = 9.1.0,<9.2.0 psutil> = 5.9.0,<5.10.0 py-cpuinfo> = 8.0.0,<8.1.0 pydantic> = 1.9.0,<1.10.0 requirement-test.txt # Pytest + plugins pytest = =7.1.2 pytest-flake8 = =1.1.1 pytest-cov = =3.0.0 # Hypothesis https://hypothesis.readthedocs.io/en/latest/data.html hypothesis> = 6.46.0,<6.47.0 # Static typechecking mypy = =0.950 lxml = =4.8.0 requirement-dev.txt -r requirements.txt -r requirements-check.txt -r requirements-docs.txt -r requirements-min.txt -r requirements-test.txt # pre-commit pre-commit = =2.18.1 check # Runs formatters and code quality checkers over your workspace. This environment is lightweight compared to devenv because it installs dependencies once and completely skips installing a package from this repository as it does not need it. The operations performed by this environment are performed in place. Info This environment is lightweight, running tox -e check often is fine. Similarly to devenv it is bullet proof in comparison to other non-utility environments (mainly test runners). It should just install on demand, and every failure should be considered and fixed permanently. pyXY # Warning pyXY - test runner envs - they require special care and you are responsible for their well being. Executes full test suite with corresponding Python interpreter version, denoted by XX numbers. All available ones are: py37 py38 py39 py310 List of included dependencies: requirement.txt click> = 8.1.0,<8.2.0 matplotlib> = 3.5.0,<3.6.0 numpy> = 1.21.0,<1.22.0 packaging> = 21.3.0,<21.4.0 pandas> = 1.3.0,<1.4.0 rich> = 12.0.0,<12.1.0 scipy> = 1.7.0,<1.8.0 tensorflow> = 2.8.0,<2.9.0 pillow> = 9.1.0,<9.2.0 psutil> = 5.9.0,<5.10.0 py-cpuinfo> = 8.0.0,<8.1.0 pydantic> = 1.9.0,<1.10.0 requirement-test.txt # Pytest + plugins pytest = =7.1.2 pytest-flake8 = =1.1.1 pytest-cov = =3.0.0 # Hypothesis https://hypothesis.readthedocs.io/en/latest/data.html hypothesis> = 6.46.0,<6.47.0 # Static typechecking mypy = =0.950 lxml = =4.8.0 mypy # Runs mypy over Python codebase to perform static type analysis. docs # Builds documentation with mkdocs, all generated files are saved to site/ folder. build-all # Builds package distribution wheels for corresponding Python version or all versions. build-all build-py37 build-py38 build-py39 build-py310 Environments with build prefix are responsible for building release packages for corresponding python versions ( build-py37 builds for Python 3.7 etc.) For each test environment ( py37 etc.) there is a corresponding build environment. Built packages (wheels) are stored in dist/ directory. Name tags list # devenv docs check py37 py38 py39 py310 mypy build-all build-py37 build-py38 build-py39 build-py310","title":"Tox usage"},{"location":"develop/tox_basics/#tox-basics","text":"A virtual environment is a Python environment such that the Python interpreter, libraries and scripts installed into it are isolated from those installed in other virtual environments, and (by default) any libraries installed in a \u201csystem\u201d Python, i.e., one which is installed as part of your operating system.","title":"Tox basics"},{"location":"develop/tox_basics/#what-is-tox","text":"tox is a generic virtualenv management and test command line tool you can use for: checking that your package installs correctly with different Python versions and interpreters running your tests in each of the environments, configuring your test tool of choice acting as a frontend to Continuous Integration servers, greatly reducing boilerplate and merging CI and shell-based testing.","title":"What is tox?"},{"location":"develop/tox_basics/#handy-links","text":"To read more about tox, visit it's documentation. tox global settings tox environments configuration tox substitutions Generating environments, conditional settings Environmental variables Full tox cli documentation tox examples","title":"Handy Links"},{"location":"develop/tox_basics/#our-perspective","text":"Every complex Python project requires multiple tools for development and deployment. Those are mostly related to test suite running, checking quality of code, developing and building documentation and building distribution packages. Usually those are tedious tasks and they are at the top of the lists of tasks to automate. Here comes tox tox can be used as a reliable replacement for manually written scripts. It's designed to run predefined series of command in automatically generated Python virtual environment. It was designed for Python ecosystem and is widely used along Python projects. It is compatible with other Python tools out of the box. All the configuration is contained in tox.ini file and is completely static.","title":"Our perspective"},{"location":"develop/tox_basics/#basic-usage","text":"To invoke single environment with tox you have to memorize one simple command: tox -e envname Where envname is replaced 1:1 with name of any environments listed below. Info You can also use tox command without any arguments to run checks for all supported python versions. Be aware that it is really time consuming.","title":"Basic usage"},{"location":"develop/tox_basics/#list-of-all-configured-environments","text":"Simplicity of creating tox managed environments allows us to create highly specialized environments with minimal boilerplate.","title":"List of all configured environments"},{"location":"develop/tox_basics/#devenv","text":"Stands for development environment (important when using IDE like Visual Studio Code or PyCharm). When selecting interpreter for your IDE, devenv is a right one to pick. This environment is meant to contain all tools important for continuos development including linters, formatters, building tools, packaging tools and everything else listed in requirements-dev.txt It is really heavy and expensive to create because of complexity of installation. Every call of tox -e devenv will completely recreate the environment. Danger Running tox -e devenv completely reinstalls environment - it's time consuming. It is designed in such way many due to the fact that during development there is no need to recreate it until something brakes, and then it's handy to simplify reinstallation how much possible. Hint Running this environment will install pre-commit. To select Python from devenv as interpreter in Visual Studio Code, use Ctrl + Shift + P and type Python: Select Interpreter , then hit Enter , select Enter interpreter path , pick Find and navigate to python.exe in .tox/devenv/bin (unix) or .tox/devev/scripts (windows). This environment is rather bullet proof in comparison to other non-utility environments (mainly test runners). It should just install on demand, and every failure should be considered and fixed permanently. List of included dependencies: requirement.txt click> = 8.1.0,<8.2.0 matplotlib> = 3.5.0,<3.6.0 numpy> = 1.21.0,<1.22.0 packaging> = 21.3.0,<21.4.0 pandas> = 1.3.0,<1.4.0 rich> = 12.0.0,<12.1.0 scipy> = 1.7.0,<1.8.0 tensorflow> = 2.8.0,<2.9.0 pillow> = 9.1.0,<9.2.0 psutil> = 5.9.0,<5.10.0 py-cpuinfo> = 8.0.0,<8.1.0 pydantic> = 1.9.0,<1.10.0 requirement-test.txt # Pytest + plugins pytest = =7.1.2 pytest-flake8 = =1.1.1 pytest-cov = =3.0.0 # Hypothesis https://hypothesis.readthedocs.io/en/latest/data.html hypothesis> = 6.46.0,<6.47.0 # Static typechecking mypy = =0.950 lxml = =4.8.0 requirement-dev.txt -r requirements.txt -r requirements-check.txt -r requirements-docs.txt -r requirements-min.txt -r requirements-test.txt # pre-commit pre-commit = =2.18.1","title":"devenv"},{"location":"develop/tox_basics/#check","text":"Runs formatters and code quality checkers over your workspace. This environment is lightweight compared to devenv because it installs dependencies once and completely skips installing a package from this repository as it does not need it. The operations performed by this environment are performed in place. Info This environment is lightweight, running tox -e check often is fine. Similarly to devenv it is bullet proof in comparison to other non-utility environments (mainly test runners). It should just install on demand, and every failure should be considered and fixed permanently.","title":"check"},{"location":"develop/tox_basics/#pyxy","text":"Warning pyXY - test runner envs - they require special care and you are responsible for their well being. Executes full test suite with corresponding Python interpreter version, denoted by XX numbers. All available ones are: py37 py38 py39 py310 List of included dependencies: requirement.txt click> = 8.1.0,<8.2.0 matplotlib> = 3.5.0,<3.6.0 numpy> = 1.21.0,<1.22.0 packaging> = 21.3.0,<21.4.0 pandas> = 1.3.0,<1.4.0 rich> = 12.0.0,<12.1.0 scipy> = 1.7.0,<1.8.0 tensorflow> = 2.8.0,<2.9.0 pillow> = 9.1.0,<9.2.0 psutil> = 5.9.0,<5.10.0 py-cpuinfo> = 8.0.0,<8.1.0 pydantic> = 1.9.0,<1.10.0 requirement-test.txt # Pytest + plugins pytest = =7.1.2 pytest-flake8 = =1.1.1 pytest-cov = =3.0.0 # Hypothesis https://hypothesis.readthedocs.io/en/latest/data.html hypothesis> = 6.46.0,<6.47.0 # Static typechecking mypy = =0.950 lxml = =4.8.0","title":"pyXY"},{"location":"develop/tox_basics/#mypy","text":"Runs mypy over Python codebase to perform static type analysis.","title":"mypy"},{"location":"develop/tox_basics/#docs","text":"Builds documentation with mkdocs, all generated files are saved to site/ folder.","title":"docs"},{"location":"develop/tox_basics/#build-all","text":"Builds package distribution wheels for corresponding Python version or all versions. build-all build-py37 build-py38 build-py39 build-py310 Environments with build prefix are responsible for building release packages for corresponding python versions ( build-py37 builds for Python 3.7 etc.) For each test environment ( py37 etc.) there is a corresponding build environment. Built packages (wheels) are stored in dist/ directory.","title":"build-all"},{"location":"develop/tox_basics/#name-tags-list","text":"devenv docs check py37 py38 py39 py310 mypy build-all build-py37 build-py38 build-py39 build-py310","title":"Name tags list"}]}